{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞\" data-toc-modified-id=\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞</a></span></li><li><span><a href=\"#–û–±—É—á–µ–Ω–∏–µ\" data-toc-modified-id=\"–û–±—É—á–µ–Ω–∏–µ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>–û–±—É—á–µ–Ω–∏–µ</a></span></li><li><span><a href=\"#–í—ã–≤–æ–¥—ã\" data-toc-modified-id=\"–í—ã–≤–æ–¥—ã-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>–í—ã–≤–æ–¥—ã</a></span></li><li><span><a href=\"#–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏\" data-toc-modified-id=\"–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>–ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –ö–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. \n",
    "\n",
    "**–ó–∞–¥–∞—á–∞:** –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é.\n",
    "\n",
    "**–¶–µ–ª—å:** –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ F1 >= 0.75.\n",
    "\n",
    "**–ü–ª–∞–Ω:**\n",
    "\n",
    "- –û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö.\n",
    "- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.\n",
    "\n",
    "**–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**\n",
    "\n",
    "–§–∞–π–ª - `toxic_comments.csv`. \n",
    "- –°—Ç–æ–ª–±–µ—Ü *text* - —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è.\n",
    "- –°—Ç–æ–ª–±–µ—Ü *toxic* ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv', index_col=0)\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å - —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Å—Ç–æ–ª–±—Ü–∞  `Unnamed: 0` –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –º–æ–∂–Ω–æ —Ç–∞–∫:\n",
    "\n",
    "\n",
    "    pd.read_csv(..., index_col=0)\n",
    "\n",
    "    \n",
    "(`Unnamed: 0` –ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –Ω–µ —Å–æ–≤—Å–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞)    \n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>\"Just to add Kansas Bear.When I said:\\n\\n\"\"You...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84755</th>\n",
       "      <td>edit again so I will have to</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49509</th>\n",
       "      <td>Re:Move\\nI read the arguments and judged that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144456</th>\n",
       "      <td>Apology \\n\\nOk, After a chance meeting with ag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88140</th>\n",
       "      <td>cited material censorship \\nwhy, duncharris an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135735</th>\n",
       "      <td>June 28, 2005 23:23 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113678</th>\n",
       "      <td>\" (UTC)\\n\\n If one takes that attitude, it nev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53146</th>\n",
       "      <td>please reffer tkz.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58752</th>\n",
       "      <td>That probably is because you haven't specified...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103639</th>\n",
       "      <td>Fuck's sake, I didn't even edit the article!  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Hi Collectonian, it obviously wasn't appropria...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106293</th>\n",
       "      <td>\"\\nWelcome!\\n\\nHello, , and welcome to Wikiped...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138985</th>\n",
       "      <td>I am God and Good\\nI'm the new master of wikim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22460</th>\n",
       "      <td>\"\\n\\nBarnstars awarded!\\n\\n  The Random Acts o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136622</th>\n",
       "      <td>|listas = Mount Baker Hard Core</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "966     \"Just to add Kansas Bear.When I said:\\n\\n\"\"You...      0\n",
       "84755                        edit again so I will have to      0\n",
       "49509   Re:Move\\nI read the arguments and judged that ...      0\n",
       "144456  Apology \\n\\nOk, After a chance meeting with ag...      0\n",
       "88140   cited material censorship \\nwhy, duncharris an...      0\n",
       "135735                          June 28, 2005 23:23 (UTC)      0\n",
       "113678  \" (UTC)\\n\\n If one takes that attitude, it nev...      0\n",
       "53146                               please reffer tkz.jpg      0\n",
       "58752   That probably is because you haven't specified...      0\n",
       "103639  Fuck's sake, I didn't even edit the article!  ...      1\n",
       "404     Hi Collectonian, it obviously wasn't appropria...      0\n",
       "106293  \"\\nWelcome!\\n\\nHello, , and welcome to Wikiped...      0\n",
       "138985  I am God and Good\\nI'm the new master of wikim...      0\n",
       "22460   \"\\n\\nBarnstars awarded!\\n\\n  The Random Acts o...      0\n",
       "136622                    |listas = Mount Baker Hard Core      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–≤–µ—Ä–∏–º –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î—É–±–ª–∏–∫–∞—Ç–æ–≤: 0\n",
      "–ü—Ä–æ–ø—É—Å–∫–æ–≤: text     0\n",
      "toxic    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('–î—É–±–ª–∏–∫–∞—Ç–æ–≤:', data.duplicated().sum())\n",
    "print('–ü—Ä–æ–ø—É—Å–∫–æ–≤:', data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–Ω–Ω—ã—Ö 159 292 –æ–±—ä–µ–∫—Ç–∞. –ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ—Ç, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º —Å–∫–æ–ª—å–∫–æ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∏ –Ω–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data['toxic'].value_counts())\n",
    "\n",
    "ratio = data['toxic'].value_counts()[0] / data['toxic'].value_counts()[1]\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ü–µ–ª–µ–≤–æ–º –ø—Ä–∏–∑–Ω–∞–∫–µ 90% –æ–±—ä–µ–∫—Ç–æ–≤ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–£—Å–ø–µ—Ö:\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –∏–∑—É—á–µ–Ω—ã. –ù–µ–±–æ–ª—å—à–æ–π EDA –Ω–µ –ø–æ–º–µ—à–∞–µ—Ç, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–µ–∫—Ç. \n",
    "\n",
    "\n",
    "–ü–ª—é—Å –∑–∞\n",
    "\n",
    "    \n",
    "\n",
    "-  –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å \n",
    "\n",
    "\n",
    "\n",
    "- –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Ü–µ —Ä–∞–∑–¥–µ–ª–∞\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- .sample() –≤–º–µ—Å—Ç–æ .head(), –≤–µ–¥—å –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫–∏–º —Ç–æ –æ–±—Ä–∞–∑–æ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã, —Ç–æ —à–∞–Ω—Å—ã —É–≤–∏–¥–µ—Ç—å —á—Ç–æ —Ç–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–µ —á–µ—Ä–µ–∑ .sample —á—É—Ç—å –≤—ã—à–µ —á–µ–º —á–µ—Ä–µ–∑ .head (–∏–ª–∏ .tail)     \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"2\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "\n",
    "–ì–æ—Ç–æ–≤–æ, —Å–ø–∞—Å–∏–±–æ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞V2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–£—Å–ø–µ—Ö üëç:\n",
    "\n",
    "\n",
    "\n",
    "üëç\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—á–∏—Å—Ç–∏–º —Ç–µ–∫—Å—Ç—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –ª–µ–º–º–∞–ª–∏–∑–∏—Ä—É–µ–º"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower()\n",
    "    lemm_text = \"\".join(lemmatizer.lemmatize(text))\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())\n",
    "\n",
    "data['lemm_text'] = data['text'].apply(lemmatize_text)\n",
    "\n",
    "data = data.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–û—à–∏–±–∫–∞:\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer  —Ä–∞–±–æ—á–∏–π –≤–∞—Ä–∏–∞–Ω—Ç, –Ω–æ —É –Ω–µ–≥–æ –µ—Å—Ç—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –µ–º—É –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–ª–æ–≤–æ, –Ω–æ –∏ POS-—Ç–µ–≥ (Part of Speech, —á–∞—Å—Ç–∏ —Ä–µ—á–∏). –ù–∞–±–∏—Ä–∞–µ–º—Å—è —É–º–∞-—Ä–∞–∑—É–º–∞ [—Ç—É—Ç](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/) )  –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—é `get_wordnet_pos`\n",
    "\n",
    "\n",
    "- –ß—Ç–æ –Ω–∞—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏? –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –º—ã –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ —Å–ª–æ–≤–∞–º, –∞ –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, WordNetLemmatizer —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.\n",
    "\n",
    "\n",
    "\n",
    "–ò —Å—Ä–∞–∑—É –ø—Ä–µ–¥—É–ø—Ä–µ–∂—É —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –ª–µ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—è–Ω–µ—Ç—Å—è –Ω–∞ –ø–æ–ª—á–∞—Å–∞ - —á–∞—Å. –ù–∏–∂–µ –ø–æ–º–æ–≥ –∫–æ–¥–æ–º\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –≤—Å–µ —ç—Ç–æ –º–æ–∂–Ω–æ –±—ã–ª–æ —Å–¥–µ–ª–∞—Ç—å —Å –ø–æ–º–æ—â—å—é SpaCy –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä–æ–º –∏ –ø—Ä—è–º–æ —Å–∫–∞–∂–µ–º –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–Ω –±–æ–ª–µ–µ —É–¥–æ–±–µ–Ω –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª–µ–Ω, –º–æ–∂–Ω–æ –ø–æ–ø–æ–¥—Ä–æ–±–Ω–µ–π —Ç—É—Ç [–ø–æ—á–∏—Ç–∞—Ç—å](https://habr.com/ru/post/531940/)  –•–æ—Ç—è –∏ –±–æ–ª–µ–µ –º–µ–¥–ª–µ–Ω–Ω—ã–π  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"2\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "\n",
    "–°–ø–∞—Å–∏–±–æ!! –ò –∑–∞ —Å—Å—ã–ª–∫–∏ —Å–ø–∞—Å–∏–±–æ! –ü—Ä–∏–º–µ–Ω–∏–º —Ñ—É–Ω–∫—Ü–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º WordNetLemmatizer –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å POS#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Å–ª–æ–≤ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clear_text(text):\n",
    "    y=re.sub(r\"[^'a-zA-Z ]\", ' ', text) \n",
    "    k=\" \".join(y.split())\n",
    "    return k\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∏–º —Ä–∞–±–æ—Ç—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "text = \"The striped bats are hanging on their feet for best\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strip bat be hang on their foot for best\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_(text):\n",
    "\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])     \n",
    "    return lemmatized_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–±—ã–ª–æ\n"
     ]
    }
   ],
   "source": [
    "print('–±—ã–ª–æ')\n",
    "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "df_my = pd.DataFrame([sentence1, sentence2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—Å—Ç–∞–ª–æ –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏\n",
      "0    The strip bat be hang on their foot for best\n",
      "1       you should be ashamed of yourself go work\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('—Å—Ç–∞–ª–æ –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏')\n",
    "print(df_my[0].apply(lemm_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ–Ω–∏–º –∫ –Ω–∞—à–∏–º –¥–∞–Ω–Ω—ã–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae76d696716740af89972057b93823e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 27s, sys: 1min 53s, total: 21min 20s\n",
      "Wall time: 21min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def lemmafunction(text):\n",
    "    k=[]\n",
    "    for i in nltk.word_tokenize(text):\n",
    "        y=lemmatizer.lemmatize(i, get_wordnet_pos(i))\n",
    "        k.append(y)\n",
    "    return ' '.join(k) \n",
    "\n",
    "lemy=[]\n",
    "for i in tqdm(range(len(corpus))):\n",
    "    \n",
    "    lemy.append(lemmafunction(clear_text(corpus[i])))\n",
    "data['lemm_text']=pd.Series(lemy, index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞V2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–£—Å–ø–µ—Ö üëç:\n",
    "\n",
    "\n",
    "\n",
    "–ü—Ä–∏–Ω—è—Ç–æ.  –ù–æ —Ö–æ—á—É –∑–∞–º–µ—Ç–∏—Ç—å —á—Ç–æ —Ü–∏–∫–ª—ã –∏ –¢–æ–Ω–µ —ç—Ç–æ –Ω–µ —Å–∞–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ apply –±—ã–ª–æ –±—ã –ª—É—á—à–µ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey man I 'm really not try to edit war It 's just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page He seem to care more about the format than the actual info\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemm_text'][2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "WordNetLemmatizer –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å POS# –∫–æ–¥ —Ä–µ–≤—å—é–µ—Ä–∞\n",
    "\n",
    "\n",
    "\n",
    "# –≤–æ—Ç –∫–æ–¥ –∏–∑ —Å—Ç–∞—Ç—å–∏:\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "# [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "\n",
    "# text —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Å –ø–æ–º–æ—â—å—é  nltk.word_tokenize —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–æ–≤–∞ (w), –∞ —ç—Ç–∏ —Å–ª–æ–≤–∞ –ø–æ–¥–∞—é—Ç—Å—è –≤ \n",
    "# lemmatizer.lemmatize(w, get_wordnet_pos(w)) –∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è. –î–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º:\n",
    "\n",
    "text = \"The striped bats are hanging on their feet for best\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])\n",
    "\n",
    "\n",
    "# striped  ----->  strip  hanging------> hang  –∏—Ç–ø –∏—Ç–¥, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–æ—à–ª–∞!\n",
    "\n",
    "# –ê —Ç–µ–ø–µ—Ä—å –¥–∞–≤–∞–π —Å–ª–µ–ø–∏–º —ç—Ç–æ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:\n",
    "    \n",
    "print(' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])    )\n",
    "\n",
    "# –ö—Ä–∞—Å–æ—Ç–∞! –í—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç\n",
    "\n",
    "\n",
    "# –∞ —Ç–µ–ø–µ—Ä—å –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ —á—É—Ç—å –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é:\n",
    "\n",
    "    \n",
    "def lemm_(text):\n",
    "\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])     \n",
    "    return lemmatized_output    \n",
    "\n",
    "\n",
    "\n",
    "# –ø—Ä–æ–≤–µ—Ä–∏–º. —Å–æ–∑–¥–∞–¥–∏–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∏–∑ –¥–≤—É—Ö —Å—Ç—Ä–æ–∫:\n",
    "print('–±—ã–ª–æ')\n",
    "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "df_my = pd.DataFrame([sentence1, sentence2])\n",
    "\n",
    "print(df_my)\n",
    "\n",
    "\n",
    "print('—Å—Ç–∞–ª–æ –ø–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏')\n",
    "# –∏ –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é c –ø–æ–º–æ—â—å—é apply\n",
    "print(df_my[0].apply(lemm_))\n",
    "\n",
    "# –≤—É–∞–ª—è!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww He match this background colour I 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I 'm really not try to edit war It 's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir be my hero Any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation Why the edits make under my userna...  \n",
       "1  D'aww He match this background colour I 'm see...  \n",
       "2  Hey man I 'm really not try to edit war It 's ...  \n",
       "3  More I ca n't make any real suggestion on impr...  \n",
       "4  You sir be my hero Any chance you remember wha...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–£—Å–ø–µ—Ö:\n",
    "\n",
    "\n",
    "- –ü–ª—é—Å –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ apply, –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Ü–∏–∫–ª—ã –Ω–∞–º –Ω–∏ –∫ —á–µ–º—É.\n",
    "\n",
    "\n",
    "- –î–∞, –≤—Å–µ–≥–¥–∞ –ª—É—á—à–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å  –≤ –∏—Ç–æ–≥–µ, —Ç–∞–∫ –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "    \n",
    "- –ø–æ–ø—Ä–æ–±—É–π .progress_apply, –¥–µ–ª–∞–µ—Ç —á—Ç–æ .apply, –Ω–æ –µ—â–µ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–∞–∫–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø—Ä–æ—Ü–µ—Å—Å.  \n",
    "\n",
    "–î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏–π, —á—Ç–æ–±—ã –∑–∞—Ä–∞–±–æ—Ç–∞–ª.progress_apply –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:\n",
    "    \n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "    \n",
    "\n",
    "–ê –µ—Å–ª–∏ –¥–µ–ª–∞–µ—à—å Colab –∏ –ø—Ä–æ—Ü–µ—Å—Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏ –æ—á–∏—Å—Ç–∫–∏ –∑–∞—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–π  .parallel_apply,  –∫–æ–º—É-—Ç–æ —ç—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —É–º–µ–Ω—å—à–∏—Ç—å –≤—Ä–µ–º—è –ø—Ä–æ–≥–æ–Ω–∞ –∫–æ–¥–∞ —Ä–∞–∑ –≤ 5-7. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ: \n",
    "\n",
    "\n",
    "    \n",
    "    from pandarallel import pandarallel   \n",
    "    tqdm.pandas(desc=\"progress\")\n",
    "    pandarallel.initialize(progress_bar = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ (–∏ —É–±—Ä–∞–≤ —Å—Ç–æ–ø—Å–ª–æ–≤–∞) –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞/[–æ–±–ª–∞–∫–æ —Å–ª–æ–≤](https://habr.com/ru/post/517410/) - —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ–±—â–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–µ–º–∞—Ç–∏–∫–µ –∏ –æ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ–º—ã—Ö —Å–ª–æ–≤–∞—Ö –≤ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∏ –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Ç–≤–∏—Ç–∞—Ö –ö—Ä–æ–º–µ —Ç–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∏, —Ä–∏—Å—É–Ω–∫–∏ –¥–µ–ª–∞—é—Ç –ø—Ä–æ–µ–∫—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–µ–π\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"2\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "\n",
    "–ì–æ—Ç–æ–≤–æ, –° tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–¥–µ–ª–∏–º –≤—ã–±–æ—Ä–∫–∏. –ü–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏—è–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –ø–æ –∫–ª–∞—Å—Å–∞–º –≤ target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data.drop('toxic',axis=1)\n",
    "target=data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=42, shuffle=True,stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–£—Å–ø–µ—Ö:\n",
    "\n",
    "\n",
    "- random_state –Ω–∞ –º–µ—Å—Ç–µ\n",
    "\n",
    "\n",
    "\n",
    "- –∑–¥–æ—Ä–æ–≤–æ —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å stratify    \n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "- –µ—Å–ª–∏ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–ø–∏—Å–∞–Ω—ã–π —Ü–∏–∫–ª, —Ç–æ –Ω–∞–º –µ—â—ë –Ω—É–∂–µ–Ω –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 2)\n",
      "(39823, 2)\n",
      "(119469,)\n",
      "(39823,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏- 75%\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ - 25%\n"
     ]
    }
   ],
   "source": [
    "train_sample=features_train.shape[0]/features.shape[0]\n",
    "test_sample=features_test.shape[0]/features.shape[0]\n",
    "\n",
    "print('–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏- {:.0%}'.format(train_sample))\n",
    "print('–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ - {:.0%}'.format(test_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898384\n",
      "1    0.101616\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ax = target_train.value_counts(normalize=True)\n",
    "print(ax)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ax = target_train.value_counts().plot(kind='bar', figsize=(7, 5),\n",
    "                                                  color=\"indigo\", fontsize=15);\n",
    "ax.set_alpha(0.9)\n",
    "ax.set_title(\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\", fontsize=12)\n",
    "ax.set_ylabel(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\", fontsize=12);\n",
    "\n",
    "totals = []\n",
    "\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_height())\n",
    "\n",
    "total = sum(totals)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.17, i.get_height()-10000,  \\\n",
    "            str(round((i.get_height()/total)*100))+'%', fontsize=15,\n",
    "                color='white')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## def down_up_sample(features, target, fraction, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_down_up = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones]*repeat)\n",
    "    target_down_up = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones]*repeat)\n",
    "    \n",
    "    features_down_up_sampled, target_down_up_sampled = shuffle(\n",
    "        features_down_up, target_down_up, random_state=12345)\n",
    "    \n",
    "    return features_down_up_sampled, target_down_up_sampled\n",
    "\n",
    "features_upsampled, target_upsampled  = down_up_sample(features_train, target_train, 0.5, 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ax = target_upsampled.value_counts(normalize=True)\n",
    "print(ax)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ax = target_upsampled.value_counts().plot(kind='bar', figsize=(7, 5),\n",
    "                                                  color=\"indigo\", fontsize=15);\n",
    "ax.set_alpha(0.9)\n",
    "ax.set_title(\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\", fontsize=12)\n",
    "ax.set_ylabel(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ\", fontsize=12);\n",
    "\n",
    "totals = []\n",
    "\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_height())\n",
    "\n",
    "total = sum(totals)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.17, i.get_height()-10000,  \\\n",
    "            str(round((i.get_height()/total)*100))+'%', fontsize=15,\n",
    "                color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'].values.astype('U'))\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'].values.astype('U'))\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "cv_counts = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–û—à–∏–±–∫–∞:\n",
    "\n",
    "\n",
    "\n",
    "–î–∞, –≤ —Ç—Ä–µ–Ω–∞–∂–µ—Ä–µ –±—ã–ª —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∏—Ä–∏–ª–∏—Ü–µ, —Ç–∞–º –ø–µ—Ä–µ–≤–æ–¥ –≤ unicode –æ–ø—Ä–∞–≤–¥–∞–Ω. –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ (–ª–∞—Ç–∏–Ω–∏—Ü–∞) —ç—Ç–æ –ª–∏—à—å  —É–≤–µ–ª–∏—á–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç—Ä–µ–±–ª—è–µ–º–æ–π –ø–∞–º—è—Ç–∏ –∏ —ç—Ç–æ –≤ –ª—É—á—à–µ–º —Å–ª—É—á–∞–∏, –≤ —Ö—É–¥—à–µ–º –æ–Ω –æ–±—Ä—É—à–∞–µ—Ç —è–¥—Ä–æ.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"2\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "\n",
    "–î–∞, —Å–ø–∞—Å–∏–±–æ, –ø–æ–Ω—è–ª–∞, –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ –æ–ø—Ä–∞–≤–¥–∞–Ω —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞V2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–£—Å–ø–µ—Ö üëç:\n",
    "\n",
    "\n",
    "\n",
    "—ç–∫–æ–Ω–æ–º–∏–º —Ä–µ—Å—É—Ä—Å—ã\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–£—Å–ø–µ—Ö:\n",
    "\n",
    "\n",
    "–ù–µ –∑–∞–±—ã–ª–∏ –æ —Å—Ç–æ–ø—Å–ª–æ–≤–∞—Ö, –æ–Ω–∏ –Ω–∏ –∫ —á–µ–º—É –∏ –∫–æ–¥ –ø–æ–±–µ–∂–∏—Ç –±—ã—Å—Ç—Ä–µ–π\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç:     \n",
    "\n",
    "–í–æ–ø—Ä–æ—Å–∏–∫:\n",
    "\n",
    "–ê —Å—Ç–æ–ø—Å–ª–æ–≤–∞ –≤–∞–∂–Ω–µ–π —É–±–∏—Ä–∞—Ç—å  –∫–æ–≥–¥–∞ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º TF-IDF, –∏–ª–∏ –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ –æ–±—ã—á–Ω—ã–π CountVectorizer? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫, –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É–µ–Ω–∏—è, –≤ —Ç–æ–º —á–∏—Å–ª–µ:\n",
    "- –ü–æ–≤–µ—Ä–∏–ª–∏ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã.\n",
    "- –û—á–∏—Å—Ç–∏–ª–∏ —Ç–µ–∫—Å—Ç—ã –æ—Ç–∑—ã–≤–æ–≤ –∏ –ª–µ–º–º–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏.\n",
    "- –ü–æ–ª—É—á–∏–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, —Ä–∞–∑–¥–µ–ª–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é, —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–£—Å–ø–µ—Ö üëç:\n",
    "\n",
    "\n",
    "\n",
    "–ó–¥–æ—Ä–æ–≤–æ —á—Ç–æ –≤ –∫–∞–∂–¥–æ–º —Ä–∞–∑–¥–µ–ª–µ –æ—Å—Ç–∞–≤–ª—è–µ—à—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –≤—ã–≤–æ–¥\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"2\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "\n",
    "–ü–µ—á–∞–ª—å–Ω–æ –∫–æ–Ω–µ—á–Ω–æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞V2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç ü§î:\n",
    "\n",
    "\n",
    "\n",
    "–ë–æ–∂–µ –º–æ–π. –Ø  –∏—Å–ø–æ–ª—å–∑—É—é –¥–∏–∫—Ç–æ–≤–∫—É —Å –≥–æ–ª–æ—Å–∞, –∏ –æ–Ω –∏–Ω–æ–≥–¥–∞ —Ç–∞–∫–æ–µ –ø–∏—à–µ—Ç...–ù–µ –∑–∞–º–µ—Ç–∏–ª, —Ç—ã—Å—è—á–∞ –∏–∑–≤–∏–Ω–µ–Ω–∏–π ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## best_model_dt = None\n",
    "best_result_dt = 0\n",
    "best_depth_dt=0\n",
    "for depth in range(1, 25, 3):\n",
    "      \n",
    "    model_dt = DecisionTreeClassifier(random_state=12345, max_depth=depth,class_weight='balanced') \n",
    "    model_dt.fit(features_train,target_train) \n",
    "    predict_dt=model_dt.predict(features_test) \n",
    "    result_dt = f1_score(target_test, predict_dt)\n",
    "    if result_dt > best_result_dt:\n",
    "        best_model_dt = model_dt\n",
    "        best_result_dt = result_dt \n",
    "          \n",
    "        best_depth_dt = depth\n",
    "print(\"F1 –Ω–∞–∏–ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Ä–∞–≤–Ω–æ:\", best_result_dt.round(2), end='')\n",
    "print(' C –≥–ª—É–±–∏–Ω–æ–π:',best_depth_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–û—à–∏–±–∫–∞:\n",
    " \n",
    "–í–æ-–ø–µ—Ä–≤—ã—Ö. –†–∞–±–æ—Ç–∞ –ù–ï –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏: \n",
    "\n",
    "\n",
    "\n",
    " - –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ\n",
    " - –ø–æ–ª—É—á–µ–Ω–∞ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
    " - –ø–µ—Ä–µ–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –≤ —Ü–∏–∫–ª–µ\n",
    "\n",
    "\n",
    "–ß—Ç–æ –∏–º–µ–Ω–Ω–æ –î–æ–≥–∞–¥–∞–π—Å—è —Å–∞–º–∞ )    \n",
    "    \n",
    "    \n",
    "–í–æ-–≤—Ç–æ—Ä—ã—Ö\n",
    "    \n",
    "    \n",
    "–ü–æ–∫–∞ –Ω–µ –≤—ã–±–µ—Ä–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –Ω–∞—Å –∫–∞–∫ –±—É–¥—Ç–æ –±—ã –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç    \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "–°–æ–≤–µ—Ç:\n",
    "    \n",
    "    \n",
    "–°–æ–≤–µ—Ç—É—é –∑–∞–±—ã—Ç—å  –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–ø–∏—Å–∞–Ω–Ω—ã–µ —Ü–∏–∫–ª –∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥—à–Ω–∞—Ç—å –∏—Å–ø–æ–ª—å–∑—É—è  GridSearchCV   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"2\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "\n",
    "–û–±—É—á–∏–º –º–æ–¥–µ–ª–∏ LogisticRegression –∏ LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
      "0.7785597134181806\n"
     ]
    }
   ],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression(random_state=12345))])\n",
    "\n",
    "params = {'clf__C': [0.1, 1, 10, 100],\n",
    "          'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "lr_grid = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1, refit=False)\n",
    "lr_grid.fit(features_train['text'], target_train)\n",
    "lr_best_paramms = lr_grid.best_params_\n",
    "\n",
    "print(lr_best_paramms)\n",
    "print(lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫, –ª—É—á—à–∏–π best_score –º–µ—Ç—Ä–∏–∫–∏ 0,77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞V2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–£—Å–ø–µ—Ö üëç:\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "–¢–æ —á—Ç–æ —Ç—ã —Å —Ä—É—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å—Ä–∞–∑—É –ø–µ—Ä–µ—Å–∫–æ—á–∏–ª–∞ –Ω–∞ GS+pipeline, —ç—Ç–æ –±–æ–ª—å—à–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å. –¢–µ–ø–µ—Ä—å –≤—Å—ë –ø–æ —Ñ—ç–Ω—à—É—é\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç:  \n",
    "\n",
    "\n",
    "\n",
    "–ù–∞ –±—É–¥—É—â–µ–µ    \n",
    "    \n",
    "    \n",
    "- –°–æ–≤–µ—Ç 1\n",
    "    \n",
    "    \n",
    "–ö–∞–∫ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ pipeline (–º—ã –ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –∏–∑ sklearn - Scaler, MinMax, –∏–ª–∏ –∫–∞–∫ –≤ —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ TFIDF –∏—Ç–ø)    \n",
    "\n",
    "\n",
    "–ú–æ–∂–µ—à—å –≤–∑—è—Ç—å –∑–∞ –æ—Å–Ω–æ–≤—É [–°—Å—ã–ª–∫–∞ 1](https://dzen.ru/media/id/5ee6f73b7cadb75a66e4c7e3/sozdanie-polzovatelskih-preobrazovatelei-dannyh-62b2a9a80e49941961ffc7a2),\n",
    "[–°—Å—ã–ª–∫–∞ 2](https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "- –°–æ–≤–µ—Ç 2  \n",
    "    \n",
    "    \n",
    "\n",
    "–ú–æ–∂–µ—à—å –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å  feature_engenering (–≠—Ç–æ –∫–æ–≥–¥–∞ –º—ã —Å–æ–∑–¥–∞—ë–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏. –í–æ –º–Ω–æ–≥–∏—Ö —Å–ª—É—á–∞—è—Ö —ç—Ç–æ –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–≤—ã—Å–∏—Ç—å –Ω–∞—à—É –º–µ—Ç—Ä–∏–∫—É,  —á–µ–º –¥–æ–ª–≥–æ –æ–±—É—á–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏) c pipeline:   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "1. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–∏—á–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–∞–ø—Ä–∏–º–µ—Ä –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∏—Å–ª–æ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ, –¥–ª–∏–Ω—É —Å–ª–æ–≤, —á–∏—Å–ª–æ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, —á–∏—Å–ª–æ —Å–ª–æ–≤ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –∏—Ç–ø –∏—Ç–¥. \n",
    "    \n",
    "   \n",
    "    \n",
    "2. –î–æ–±–∞–≤–∏—Ç—å –∫ —Ñ–∏—á–∞–º –æ—Ç –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä–∞\n",
    "    \n",
    "    \n",
    "–≠—Ç–æ –º–æ–∂–Ω–æ –±—ã–ª–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Å—Ö–µ–º–µ —á–µ—Ä–µ–∑ [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html):\n",
    "    \n",
    "    \n",
    "    new_features = ['lengh', 'number', ....]\n",
    "    # –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ –∫–æ—Ç–æ—Ä—ã—Ö —É –Ω–∞—Å –∑–∞–ø–∏—Å–∞–Ω—ã –Ω–æ–≤—ã–µ —Ñ–∏—á–∏ (lengh - –¥–æ–ø—É—Å—Ç–∏–º –¥–ª–∏–Ω–∞ —Å–ª–æ–≤ —Ç–≤–∏—Ç–∞—Ö, number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Ç–≤–∏—Ç–µ...)\n",
    "    \n",
    "    # lemmatized_text - —Å—Ç–æ–ª–±–µ—Ü —Å —Ç–µ–∫—Å—Ç–æ–º\n",
    "    \n",
    "    features = ColumnTransformer(\n",
    "                        [(\"text_preprocess\", TfidfVectorizer(stop_words=stopwords), \"lemmatized_text\"),\n",
    "                         (\"new_features_preprocess\", StandardScaler(), new_features)\n",
    "                        ])\n",
    "\n",
    "    \n",
    "    pipe = Pipeline([('features_all_prepross', features),\n",
    "                     ('model', LogisticRegression(random_state = 42))\n",
    "                    ])\n",
    "\n",
    "–ö–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, —ç—Ç–æ —Ü–µ–ª–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–æ. –°—Ç—É–¥–µ–Ω—Ç –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –±–∏–±–ª–∏–æ—Ç–µ–∫—É\n",
    "    \n",
    "    \n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer    \n",
    "\n",
    "—Å–º–æ–≥ –∑–¥–æ—Ä–æ–≤–æ –ø–æ–¥–Ω—è—Ç—å –º–µ—Ç—Ä–∏–∫—É"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–£—Å–ø–µ—Ö:\n",
    "\n",
    "–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω GridSearch \n",
    "\n",
    "\n",
    "\n",
    "- –Ω–µ –∑–∞–±—ã—Ç random_state\n",
    "\n",
    "\n",
    "- class_weight = 'balanced'\n",
    "\n",
    "\n",
    "- scoring = 'f1'\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "–ú–æ–ª–æ–¥–µ—Ü —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å GridSearch, –Ω–æ –µ—â–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤—è–∑–∫—É GridSearchCV + pipeline. \n",
    "\n",
    "\n",
    "–û pipeline:\n",
    "\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), —ç—Ç–æ —Ç–µ–º–∞ –∫–æ—Ç–æ—Ä–∞—è —Å—Ä–∞–∑—É –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—é, —Ç—é–Ω–∏–Ω–≥ \"–≤–µ–∫—Ç–æ—Ä–∞–π–∑\", –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –∏ –æ —Ç–æ–º —á—Ç–æ –∫–æ–¥ —Å—Ç–æ–∏—Ç –¥–µ–ª–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º.\n",
    "    \n",
    "    \n",
    "- –≤ TfidfVectorizer(stop_words=stopwords) —É —Ç–µ–±—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ngram_range=(1, 1), —Ç—É—Ç –º–æ–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å —Ä–∞–∑–Ω–æ–µ —á–∏—Å–ª–æ n- –≥—Ä–∞–º–º (–∏ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã), –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—è –º–µ—Ç—Ä–∏–∫—É, –Ω–æ –∫–∞–∫ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –ø–µ—Ä–µ–±–æ—Ä –ø–æ ngram_range —Å –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ü–∏–∫–ª–∞?! pipeline! –ì–æ—Ç–æ–≤—ã–π [–ø—Ä–∏–º–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–∞–º–∏](https://medium.com/@yoni.levine/how-to-grid-search-with-a-pipeline-93147835d916). –í—Å—ë —á—Ç–æ –Ω—É–∂–Ω–æ —Ç–∞–º –µ—Å—Ç—å, —Ö–æ—Ç—è –æ—á–µ–Ω—å –ª–∞–∫–æ–Ω–∏—á–Ω–æ. –ú–æ–∂–µ—à—å –ø–æ–≥—É–≥–ª–∏—Ç—å –ø–æ:\n",
    "\n",
    "\n",
    "    \n",
    "    pipeline nlp gridsearchcv\n",
    "\n",
    "\n",
    "\n",
    "- –∫–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ –ø–æ–¥–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ, –∫–æ–≥–¥–∞ –º—ã –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏ (—à–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, TfidfVectorizer –∏—Ç–ø –∏—Ç–¥)? pipeline! –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ç–æ –≤–∞–∂–Ω–æ, –∫–æ–≥–¥–∞ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—Ä–æ—Å—Å–≤–∞–ª–∏–¥–∞—Ü–∏—é. –î–ª—è TfidfVectorizer –¥–µ–ª–∞–µ–º .fit (–æ–±—É—á–∞–µ–º—Å—è) –Ω–∞ train, –∞ transform –Ω–∞ test, –Ω–æ —Ç–æ—á–Ω–æ —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏. –ù–æ GS –¥–µ–ª–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–Ω—É—Ç—Ä–∏ —Å–µ–±—è, —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ –¥–æ–±—Ä–∞—Ç—å—Å—è –¥–æ –Ω–µ–µ –∏ –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–¥–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ? –ö–∞–∑–∞–ª–æ—Å—å –±—ã –Ω–∏–∫–∞–∫, –Ω–æ –Ω–µ—Ç! Pipeline! ) \n",
    "    \n",
    "    \n",
    "- pipeline –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ–ª–∞—Ç—å –Ω–∞—à –∫–æ–¥ –∫–æ–º–ø–∞–∫—Ç–Ω–µ–π –∏ —á–∏—Ç–∞–±–µ–ª—å–Ω–µ–π, —ç—Ç–æ –±–æ–ª—å—à–æ–π –ø–ª—é—Å, –∫–æ–≥–¥–∞ –∫–æ–¥ –±—É–¥–µ—Ç —Ä–∞–∑–¥—É–≤–∞—Ç—å—Å—è     \n",
    "    \n",
    "    \n",
    "\n",
    "         \n",
    "–ï—Å–ª–∏ —Ä–∞–Ω—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ pipeline —Ç–æ –º–æ–≥—É –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ –≤ –∫–æ—Ç–æ—Ä–æ–º [–∏–Ω–¥—É—Å](https://www.youtube.com/watch?v=mOYJCR0IDk8&ab_channel=HimanshuChandra) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å —Å–∏–ª—å–Ω—ã–º –∞–∫—Ü–µ–Ω—Ç–æ–º, –Ω–æ –Ω–∞ –ø–∞–ª—å—Ü–∞—Ö –æ–±—å—è—Å–Ω—è–µ—Ç  —Å–∞–º–æ–µ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–µ (–ø–æ –º–æ–µ–º—É –æ–ø—ã—Ç—É): —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤ fit –∏ transform. –¢–∞–º –∂–µ –µ—Å—Ç—å –∏ –∫–æ–¥ –∏ —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–µ–∫—Å—Ç. –ú–Ω–µ –ø–æ–º–æ–≥–ª–æ )\n",
    "\n",
    "\n",
    "\n",
    "–í –æ–±—â–µ–º –µ—Å–ª–∏ —Å–¥–µ–ª–∞—Ç—å GS+pipeline –±—É–¥–µ—Ç –≤–æ–æ–±—â–µ —Ö–æ—Ä–æ—à–æ )  \n",
    "    \n",
    "<div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–û—à–∏–±–∫–∞ ‚ùå:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å–∞–º—ã–π –∫–æ–Ω–µ—Ü\n",
    "    \n",
    "    \n",
    "- –ù–∞–¥–æ –≤—ã–≤–µ—Å—Ç–∏ .best_score_ -  –≠—Ç–æ –µ—Å—Ç—å –ú–µ—Ç—Ä–∏–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ–≥–¥–∞ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º GS  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## best_model_rf = None\n",
    "best_result_rf = 0\n",
    "best_depth_rf=0\n",
    "for est in range(1, 12, 4):\n",
    "      \n",
    "    model_rf = RandomForestClassifier(random_state=12345, n_estimators=est, class_weight='balanced_subsample') \n",
    "    model_rf.fit(features_train,target_train) \n",
    "    predict_rf=model_rf.predict(features_test) \n",
    "    result_rf = f1_score(target_test, predict_rf)\n",
    "    if result_rf > best_result_rf:\n",
    "        best_model_rf = model_rf\n",
    "        best_result_rf = result_rf\n",
    "          \n",
    "        best_depth_rf = est\n",
    "print(\"F1 –Ω–∞–∏–ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Ä–∞–≤–Ω–æ:\", best_result_rf.round(2), end='')\n",
    "print(' C –≥–ª—É–±–∏–Ω–æ–π:',best_depth_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç ü§î:\n",
    "\n",
    "–°–æ–≤–µ—Ç—ã –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏   \n",
    "\n",
    "\n",
    "- –î–µ—Ä–µ–≤—è–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (RF, DT) –º–µ–¥–ª–µ–Ω–Ω—ã–µ, –∏ –Ω–∞ –¥–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑—É–π –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –∏ LightGBM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –°–æ–≤–µ—Ç—É—é —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è —É –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ –ø–µ—Ä–µ–±–æ—Ä–µ \"C\", –∞ max_iter –∏ solver –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–µ–Ω—å–∫–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç, –ª—É—á—à–µ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å. \n",
    "\n",
    "\n",
    "- –ù–µ –∑–∞–±—ã–≤–∞–µ–º n_jobs = -1 (–ò–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç). –£ LightGBM –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±—É–π —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å num_threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__learning_rate': 0.25, 'clf__max_depth': -1, 'clf__n_estimators': 50}\n",
      "0.7553530236307816\n"
     ]
    }
   ],
   "source": [
    "lgb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LGBMClassifier(random_state=12345))])\n",
    "\n",
    "params = {\n",
    "  'clf__n_estimators': [50],\n",
    "  'clf__learning_rate': [0.15, 0.25],\n",
    "  'clf__max_depth': [6, 8, -1]}\n",
    "\n",
    "lgb_grid = GridSearchCV(estimator=lgb_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1, refit=False)\n",
    "lgb_grid.fit(features_train['text'], target_train)\n",
    "lgb_best_params = lgb_grid.best_params_\n",
    "\n",
    "print(lgb_best_params)\n",
    "print(lgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ—É—á—à–∏–π best_score_ –º–µ—Ç—Ä–∏–∫–∏ —É –º–æ–¥–µ–ª–∏ LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(ngram_range=(1,3),\n",
    "               min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = vectorize.fit_transform(features_train['text'])\n",
    "features_test = vectorize.transform(features_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', random_state=12345)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_t = LogisticRegression(C=10, class_weight='balanced', random_state=12345)\n",
    "lr_t.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "    \n",
    "    \n",
    "–°–æ–≤–µ—Ç:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "–ù–µ –Ω–∞–¥–æ –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å  GS –∫–∞–∫ —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∏—Ç—å .best_params_, —á—Ç–æ–±—ã –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å –∏—Ö –≤ –º–æ–¥–µ–ª—å –∏ –æ–±—É—á–∏—Ç—å –Ω–∞ –Ω–∏—Ö. GS —ç—Ç–æ —Å–¥–µ–ª–∞–ª —É–∂–µ –∏ –º–æ–¥–µ–ª—å–∫—É –ø–æ–ª–æ–∂–∏–ª —Ç—É—Ç: .best_estimator_\n",
    "    \n",
    "  \n",
    "–¢–æ –µ—Å—Ç—å –≤–æ—Ç —ç—Ç–æ –Ω–µ –Ω—É–∂–Ω–æ    \n",
    "    \n",
    "    lr_t = LogisticRegression(C=10, class_weight='balanced', random_state=12345)\n",
    "    lr_t.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lgb_t = LGBMClassifier(learning_rate=0.25, max_depth=-1, n_estimators=200, random_state = 12345)\n",
    "lgb_t.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º F1\n",
    "\n",
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'RandomForestClassifier',\n",
    "        ]\n",
    "\n",
    "data = {'F1': [f1_log_r_1, \n",
    "               f1_forest_1,\n",
    "               f1_random_forest]}\n",
    "\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "print(f1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 –Ω–∞ —Ç–µ—Å—Ç–µ: 0.79\n"
     ]
    }
   ],
   "source": [
    "test_pred = lr_t.predict(features_test)\n",
    "test_f1 = f1_score(target_test, test_pred)\n",
    "print('F1 –Ω–∞ —Ç–µ—Å—Ç–µ: {:.2f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞v2</b></font>\n",
    "\n",
    "–£—Å–ø–µ—Ö: \n",
    "\n",
    "\n",
    "\n",
    "- –ï—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª –Ω–∞ —Ç–µ—Å—Ç–µ f1 –≤—ã—à–µ 0,75, —ç—Ç–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—Ä–∏–µ–º–ª–µ–º—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "\n",
    "\n",
    "–ß—Ç–æ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –¥–æ–±–∏—Ç—å—Å—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ)? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –º–æ–∂–Ω–æ –ø–æ–∏–≥—Ä–∞—Ç—å—Å—è [–ø–æ—Ä–æ–≥–æ–º](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "- —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–∏—á–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä  –Ω–∞–ø—Ä–∏–º–µ—Ä –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∏—Å–ª–æ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ, –¥–ª–∏–Ω—É —Å–ª–æ–≤ –∏—Ç–ø –∏—Ç–¥. –ò–ª–∏ —Å –ø–æ–º–æ—â—å—é [—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è](https://pythobyte.com/python-for-nlp-topic-modeling-8fb3d689/) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –ë–µ—Ä—Ç–∞, –≤—ã–±—Ä–∞–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å –∏ –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–∏–Ω–≥–∏, –¥–∞–∂–µ –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞ test –ø–æ–∫–∞–∂–µ—Ç —Ö–æ—Ä–æ—à—É—é –º–µ—Ç—Ä–∏–∫—É. –í —ç—Ç–æ–º —Å–ª—É—á–∞–∏ –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É > 0.95 (–ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "–û—à–∏–±–∫–∞:\n",
    "\n",
    "–ê –≤–æ—Ç —Ç—É—Ç, –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ,  –≤—ã–±—Ä–∞–≤ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ - –¥–µ–ª–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ. –ò –µ—Å–ª–∏ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–Ω–∞—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –ø–æ–∫–∞–∂–µ—Ç –Ω–∞ test —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ö—É–∂–µ —Ç—Ä–µ–±—É–µ–º–æ–≥–æ, –º—ã –Ω–∞—á–Ω–µ–º –ø—Ä–æ—Ü–µ—Å—Å –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–Ω–∞—á–∞–ª–∞ (–∞ –Ω–µ –±—É–¥–µ–º —Ç–∞–∫–∏–µ - \"–∞ –¥–∞–≤–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞ —Ç–µ—Å—Ç–µ –º–æ–¥–µ–ª—å –∫–æ—Ç–æ—Ä–∞—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –±—ã–ª–∞ –ª—É—á—à–µ–π, –º–æ–∂–µ—Ç –æ–Ω–∞ –Ω–∞–º –Ω–∞ test –¥–∞—Å—Ç –Ω—É–∂–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ\").         \n",
    "    \n",
    "–ü–æ—á–µ–º—É —Ç–æ–ª—å–∫–æ –ª—É—á—à–∞—è?! –≠—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –º—ã –¥–∞–∂–µ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –Ω–µ \"–ø–æ–¥–≥–æ–Ω—è–ª–∏—Å—å\" –ø–æ–¥ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É. –í–µ–¥—å –Ω–∞ train –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞—é—Ç—Å—è, –ø–æ –≤–∞–ª–∏–¥–∏–∞—Ü–∏–∏ –ø–æ–¥–≥–æ–Ω—è—é—Ç—Å—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã. –≠—Ç–∏ –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ \"–∑–Ω–∞—é—Ç\". –ê test (out-of-sample) —ç—Ç–æ —É–∂–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∏—Ç—É–∞—Ü–∏–∏ –∫–æ–≥–¥–∞ —É –Ω–∞—Å –µ—Å—Ç—å —É–∂–µ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (–≤ —Ä–µ–ª—å–Ω–æ—Å—Ç–∏ —É –Ω–∞—Å –∂–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–æ–∫–ª—å–∫–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤, —á—Ç–æ —Ç–æ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–∏ –Ω–∞–¥–æ –≤—ã–±–∏—Ä–∞—Ç—å). –í–æ—Ç –ø–æ—ç—Ç–æ–º—É —Ç–∞–∫–∞—è –¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–≥–æ–Ω–∫—É. –ö—Ä–æ–º–µ —Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–Ω–æ–∏—Ö –º–æ–¥–µ–ª–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —ç—Ç–æ —Ç–æ–∂–µ –ø–æ–¥–≥–æ–Ω–∫–∞, –ø–æ—ç—Ç–æ–º—É –≤—ã–±–∏—Ä–∞—è –æ–¥–Ω—É –∏ —Ç–µ—Å—Ç–∏—Ä—É—è —Ç–æ–ª—å–∫–æ –µ–µ, –º—ã —Ç–µ–º —Å–∞–º—ã–º –±–æ—Ä–µ–º—Å—è —Å –ø–æ–¥–≥–æ–Ω–∫–æ–π —á–µ—Ä–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–Ω–æ–≥–∏—Ö-–º–Ω–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ö–æ—Ä–æ—à –Ω–µ –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã –¥–∞–Ω–Ω—ã–µ –ø–æ—á–∏—Å—Ç–∏–ª–∏ —Ö–æ—Ä–æ—à–æ, –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Ç–¥ –∏—Ç–ø, –∞ –ø–æ—Ç–æ–º—É —á—Ç–æ –∏–∑ –º–Ω–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π —Ö–æ—Ç—å –∫–∞–∫–∞—è —Ç–æ —Å–ª—É—á–∞–π–Ω–æ \"—Å—ã–≥—Ä–∞–µ—Ç\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫, –≤ —Ö–æ–¥–µ —Ä–∞–±–æ—Ç—ã, —Å —Ü–µ–ª—å—é –Ω–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é, –±—ã–ª–∞ –Ω–∞–π–¥–µ–Ω –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ F1 >= 0.75.\n",
    "\n",
    "–í —Ç–æ–º —á–∏—Å–ª–µ:\n",
    "\n",
    "- –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ.\n",
    "- –û—á–∏—â–µ–Ω—ã –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã —Ä–∞–∑–º–µ—Ç–∫–∞.\n",
    "- –î–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –º–µ—Ç–æ–¥–æ–º TF-IDF.\n",
    "- –†–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏- 75%. –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ - 25%).\n",
    "- –° –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ–±—É—á–µ–Ω—ã –¥–≤–µ –º–æ–¥–µ–ª–∏: LogisticRegression, LGBMClassifier. \n",
    "\n",
    "–ù–∞–∏–ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é —Å—Ç–∞–ª–∞ LogisticRegression (–ø—Ä–∏: C = 10) —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º F1 = 0.79. –ï–µ –º–æ–∂–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞</b></font>\n",
    "\n",
    "\n",
    "\n",
    "–ê–Ω—è, —É —Ç–µ–±—è —Å—Ç–∞—Ä–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞, –≤—Å–µ —á–µ—Ç–∫–æ, –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ. \n",
    "\n",
    "\n",
    "–ó–∞–º–µ—á–∞–Ω–∏—è –Ω–∞ –±—É–¥—É—â–µ–µ:\n",
    "    \n",
    "\n",
    "\n",
    "- –ì–¥–µ —Ç–æ —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å GS, –≥–¥–µ —Ç–æ –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–ø–∏—Å–∞–Ω—ã–π —Ü–∏–∫–ª. –ó–∞—á–µ–º? –ò—Å–ø–æ–ª—å–∑—É–π –≤–µ–∑–¥–µ GS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "–Ø –æ—Å—Ç–∞–≤–∏–ª –Ω–µ–±–æ–ª—å—à–∏–µ —Å–æ–≤–µ—Ç—ã –∏ –≤–æ–ø—Ä–æ—Å–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è –∏ –∂–µ–ª–∞–Ω–∏–µ –º–æ–∂–µ—à—å –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è/–æ—Ç–≤–µ—Ç–∏—Ç—å).\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å POS - —Ç–µ–≥  –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ —Å–ª–æ–≤–∞–º –∞ –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "- .astype('U') –ª–∏—à–Ω–µ–µ, —Å—Ç–æ–∏—Ç —ç–∫–æ–Ω–æ–º–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã, –∏–Ω–∞—á–µ –º–æ–∂–µ—Ç –¥–∞–∂–µ —è–¥—Ä–æ –æ–±—Ä—É—à–∏—Ç—å—Å—è\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–ø–∏—Å–∞–Ω–Ω–æ–º —Ü–∏–∫–ª–µ, —Ç–æ–≥–¥–∞ —Ç–µ–±–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –µ—â—ë –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞    \n",
    "\n",
    "\n",
    "- –Ω–∞ test –¥–∞—Ç–∞—Å–µ—Ç–µ —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (–Ω–∞—Ä—É—à–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –ø—Ä–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "–ñ–¥—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π, –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –ø—Ä–æ–µ–∫—Ç–∞. –ï—Å–ª–∏ –∫–∞–∫–∏–µ —Ç–æ –≤–æ–ø—Ä–æ—Å—ã, —Ç–æ —Å—Ä–∞–∑—É —Å–ø—Ä–∞—à–∏–≤–∞–π ) \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞V2</b></font>\n",
    "\n",
    "\n",
    "–ï—â—ë —Ä–∞–∑ –∏–∑–≤–∏–Ω—è—é—Å—å –∑–∞ \"–¥—É—Ä–∞\" ) –ò—Å–ø—Ä–∞–≤–∏–ª\n",
    "    \n",
    "    \n",
    "–°–ø–∞—Å–∏–±–æ –∑–∞ —Ä–∞–±–æ—Ç—É! –î–æ–≤–µ–ª –¥–æ —É–º–∞ pipeline, –º–æ–ª–æ–¥–µ—Ü. \n",
    "–ö—Ä–∞—Å–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ. –ù–∞–¥–µ—é—Å—å –º–æ–∏ —Å–æ–≤–µ—Ç—ã –∏ –≤–æ–ø—Ä–æ—Å–∏–∫–∏ –±—ã–ª–∏ –ø–æ–ª–µ–∑–Ω—ã –∏ –≤ –∫–æ–ø–∏–ª–æ—á–∫—É –∑–Ω–∞–Ω–∏–π —É–ø–∞–ª–æ —á—Ç–æ —Ç–æ –Ω–æ–≤–æ–µ, –∞ –ø—Ä–æ–µ–∫—Ç —Å—Ç–∞–ª –ª—É—á—à–µ, –∏ —Å–∏–º–ø–∞—Ç–∏—á–Ω–µ–π.\n",
    "\n",
    "\n",
    "  \n",
    "–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞  –ê–Ω—è. –ñ–µ–ª–∞—é —É—Å–ø–µ—Ö–æ–≤ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–π —É—á–µ–±–µ!\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "–°–æ–≤–µ—Ç: \n",
    "    \n",
    "    \n",
    "–ï—Å–ª–∏ –¥—É–º–∞–µ—à—å –∏ –¥–∞–ª—å—à–µ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è NLP, —Ç–æ –≤–ø–µ—Ä–µ–¥–∏ –æ—á–µ–Ω—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏ –º–æ–¥–Ω—ã–π —Å–µ–π—á–∞—Å –ø–æ–¥—Ö–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –æ—Ç –ë–µ—Ä—Ç. –í–æ–æ–±—â–µ –∏–º–µ–Ω–Ω–æ –≤ –ù–õ–ü —Å–µ–π—á–∞—Å —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ –ø—Ä–æ—Ä—ã–≤—ã –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏,  –º–æ–∂–µ—Ç –≤ –∫—É—Ä—Å–µ –ø—Ä–æ [chatGPT](https://www.youtube.com/watch?v=IMP1zZ9K4Wc&t=3038s), GPT - —ç—Ç–æ –±—Ä–∞—Ç–∏–∫ –ë–µ—Ä—Ç–∞ )\n",
    "\n",
    "   \n",
    "\n",
    "<font color='green'><b>–ü–æ–ª–µ–∑–Ω—ã–µ (–∏ –ø—Ä–æ—Å—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ) –º–∞—Ç–µ—Ä–∏–∞–ª—ã:</b> \\\n",
    "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∏ –¥—Ä—É–≥–∏–µ –ø–æ–¥—Ö–æ–¥—ã. –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–µ–π—á–∞—Å –∞–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è RNN (LSTM) –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã (BERT –∏ –¥—Ä—É–≥–∏–µ —Å —É–ª–∏—Ü—ã –°–µ–∑–∞–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, ELMO). –ù–û! –û–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø–∞–Ω–∞—Ü–µ–µ–π, –Ω–µ –≤—Å–µ–≥–¥–∞ –æ–Ω–∏ –Ω—É–∂–Ω—ã, —Ç–∞–∫ –∫–∞–∫ –∏ TF-IDF –∏–ª–∏ Word2Vec + –º–æ–¥–µ–ª–∏ –∏–∑ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ ML —Ç–æ–∂–µ –º–æ–≥—É—Ç —Å–ø—Ä–∞–≤–ª—è—Ç—å—Å—è. \\\n",
    "BERT —Ç—è–∂–µ–ª—ã–π, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –º–Ω–æ–≥–æ –µ–≥–æ –≤–∞—Ä–∏–∞—Ü–∏–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á, –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –µ—Å—Ç—å –Ω–∞–¥—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞–¥ –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π transformers. –ï—Å–ª–∏, –æ–±—É—á–∞—Ç—å BERT –Ω–∞ GPU (–º–æ–∂–Ω–æ –≤ Google Colab –∏–ª–∏ Kaggle), —Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–±—ã—Å—Ç—Ä–µ–µ.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - –ü—Ä–æ LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - –ø—Ä–æ —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä –º–æ–¥–µ–ª–∏, —ç—Ç–µ–Ω—à–µ–Ω—ã\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –≥–∞–π–¥\n",
    "–ø–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—É –æ—Ç —Å–æ–∑–¥–∞—Ç–µ–ª–µ–π pytorch\\\n",
    "https://transformer.huggingface.co/ - –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–º \\\n",
    "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: allennlp, fairseq, transformers, tensorflow-text ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö\n",
    "–º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –º–µ—Ç–æ–¥–æ–≤ NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "\n",
    "–ï—Å–ª–∏ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å —Ä–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —Ç–æ –º–æ–∂–µ—à—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π (–Ω–æ –æ—á–µ–Ω—å-–æ—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π) –∫—É—Ä—Å –ª–µ–∫—Ü–∏–π: https://github.com/yandexdataschool/nlp_course .\n",
    "\n",
    "–ï—Å–ª–∏ –Ω—Ä–∞–≤–∏—Ç—Å—è —Å–º–æ—Ç—Ä–µ—Ç—å –∏ —Å–ª—É—à–∞—Ç—å —Ç–æ –µ—Å—Ç—å —Ü–µ–ª—ã–π –∫—É—Ä—Å –Ω–∞ –Æ—Ç—É–±–µ https://www.youtube.com/watch?v=qDMwIQRQt-M&list=PLEwK9wdS5g0qksxWxtE5c2KuFkIfUXe3i&index=1\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook –æ—Ç–∫—Ä—ã—Ç\n",
    "- [x]  –í–µ—Å—å –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫\n",
    "- [x]  –Ø—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "- [x]  –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã\n",
    "- [x]  –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã\n",
    "- [x]  –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75\n",
    "- [x]  –í—ã–≤–æ–¥—ã –Ω–∞–ø–∏—Å–∞–Ω—ã"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1932,
    "start_time": "2023-02-20T09:13:04.892Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-20T09:14:02.964Z"
   },
   {
    "duration": 177,
    "start_time": "2023-02-20T09:16:39.841Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-20T09:16:56.643Z"
   },
   {
    "duration": 2481,
    "start_time": "2023-02-20T09:17:33.730Z"
   },
   {
    "duration": 37,
    "start_time": "2023-02-20T09:17:37.252Z"
   },
   {
    "duration": 127,
    "start_time": "2023-02-20T09:20:11.856Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-20T09:20:33.576Z"
   },
   {
    "duration": 244,
    "start_time": "2023-02-20T09:24:53.844Z"
   },
   {
    "duration": 201,
    "start_time": "2023-02-20T09:25:43.884Z"
   },
   {
    "duration": 224,
    "start_time": "2023-02-20T09:25:52.109Z"
   },
   {
    "duration": 225,
    "start_time": "2023-02-20T09:26:17.070Z"
   },
   {
    "duration": 70,
    "start_time": "2023-02-20T09:27:22.214Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-20T09:31:50.157Z"
   },
   {
    "duration": 4222,
    "start_time": "2023-02-20T09:31:52.219Z"
   },
   {
    "duration": 3490,
    "start_time": "2023-02-20T09:32:23.051Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-20T09:33:22.021Z"
   },
   {
    "duration": 361,
    "start_time": "2023-02-20T09:33:40.869Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-20T09:35:48.375Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-20T09:35:52.423Z"
   },
   {
    "duration": 334,
    "start_time": "2023-02-20T09:35:55.159Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-20T09:36:36.799Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-20T09:36:38.392Z"
   },
   {
    "duration": 424,
    "start_time": "2023-02-20T09:36:40.528Z"
   },
   {
    "duration": 147,
    "start_time": "2023-02-20T09:37:25.873Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-20T09:37:27.752Z"
   },
   {
    "duration": 412,
    "start_time": "2023-02-20T09:37:30.201Z"
   },
   {
    "duration": 6124,
    "start_time": "2023-02-20T09:39:38.657Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-20T09:40:11.383Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-20T09:40:54.099Z"
   },
   {
    "duration": 1651,
    "start_time": "2023-02-20T09:40:59.683Z"
   },
   {
    "duration": 2370,
    "start_time": "2023-02-20T09:41:21.596Z"
   },
   {
    "duration": 2510,
    "start_time": "2023-02-20T09:42:00.998Z"
   },
   {
    "duration": 1502,
    "start_time": "2023-02-20T09:42:50.916Z"
   },
   {
    "duration": 920,
    "start_time": "2023-02-20T09:42:53.772Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-20T09:42:56.300Z"
   },
   {
    "duration": 272,
    "start_time": "2023-02-20T09:42:59.028Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-20T09:43:01.982Z"
   },
   {
    "duration": 7537,
    "start_time": "2023-02-20T09:43:04.877Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-20T09:43:21.445Z"
   },
   {
    "duration": 1669,
    "start_time": "2023-03-06T06:56:51.337Z"
   },
   {
    "duration": 2612,
    "start_time": "2023-03-06T06:56:53.471Z"
   },
   {
    "duration": 47,
    "start_time": "2023-03-06T06:56:57.880Z"
   },
   {
    "duration": 240,
    "start_time": "2023-03-06T06:57:00.232Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-06T06:57:02.345Z"
   },
   {
    "duration": 6855,
    "start_time": "2023-03-06T06:57:04.112Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-06T06:57:12.384Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-06T06:58:29.490Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-06T06:58:43.308Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-06T07:03:19.152Z"
   },
   {
    "duration": 71,
    "start_time": "2023-03-06T07:04:10.416Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-06T07:04:28.529Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-06T07:05:52.009Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-06T07:06:30.603Z"
   },
   {
    "duration": 97,
    "start_time": "2023-03-06T07:06:47.211Z"
   },
   {
    "duration": 1627,
    "start_time": "2023-03-23T05:32:59.142Z"
   },
   {
    "duration": 1244,
    "start_time": "2023-03-23T05:33:02.052Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-23T05:33:04.853Z"
   },
   {
    "duration": 266,
    "start_time": "2023-03-23T05:33:07.397Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-23T05:33:09.233Z"
   },
   {
    "duration": 6427,
    "start_time": "2023-03-23T05:33:12.948Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-23T05:33:19.835Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T05:34:52.525Z"
   },
   {
    "duration": 116,
    "start_time": "2023-03-23T05:37:01.929Z"
   },
   {
    "duration": 66,
    "start_time": "2023-03-23T05:37:23.134Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-23T05:39:28.787Z"
   },
   {
    "duration": 108,
    "start_time": "2023-03-23T05:48:01.831Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-23T05:48:22.729Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-23T05:49:09.181Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T05:50:29.549Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-23T05:50:59.834Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-23T05:51:05.048Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-23T05:51:32.217Z"
   },
   {
    "duration": 87,
    "start_time": "2023-03-23T05:51:56.784Z"
   },
   {
    "duration": 1593,
    "start_time": "2023-03-23T05:53:25.586Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-23T05:54:52.723Z"
   },
   {
    "duration": 532,
    "start_time": "2023-03-23T05:56:06.727Z"
   },
   {
    "duration": 171,
    "start_time": "2023-03-23T05:59:07.449Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-23T06:01:03.442Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T06:01:32.186Z"
   },
   {
    "duration": 6198,
    "start_time": "2023-03-23T06:03:59.389Z"
   },
   {
    "duration": 5903,
    "start_time": "2023-03-23T06:04:38.334Z"
   },
   {
    "duration": 2165,
    "start_time": "2023-03-23T06:04:55.342Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T07:11:07.355Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-23T07:12:08.938Z"
   },
   {
    "duration": 851,
    "start_time": "2023-03-23T07:12:10.483Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-23T07:13:42.244Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T07:15:00.287Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T07:22:24.407Z"
   },
   {
    "duration": 713,
    "start_time": "2023-03-23T07:22:28.128Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-23T07:24:00.125Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-23T07:25:46.059Z"
   },
   {
    "duration": 415,
    "start_time": "2023-03-23T07:25:48.430Z"
   },
   {
    "duration": 43855,
    "start_time": "2023-03-23T07:26:58.431Z"
   },
   {
    "duration": 10921,
    "start_time": "2023-03-23T07:30:34.623Z"
   },
   {
    "duration": 11639,
    "start_time": "2023-03-23T07:31:29.376Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-23T07:32:23.875Z"
   },
   {
    "duration": 12440,
    "start_time": "2023-03-23T07:32:25.690Z"
   },
   {
    "duration": 44561,
    "start_time": "2023-03-23T07:43:58.850Z"
   },
   {
    "duration": 297,
    "start_time": "2023-03-23T08:20:23.866Z"
   },
   {
    "duration": 66385,
    "start_time": "2023-03-23T08:43:13.048Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-23T08:44:59.730Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-23T08:45:25.451Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-23T08:55:40.702Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-23T08:56:03.398Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-23T08:57:12.503Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-23T08:57:45.714Z"
   },
   {
    "duration": 392803,
    "start_time": "2023-03-23T08:57:48.935Z"
   },
   {
    "duration": 489,
    "start_time": "2023-03-23T09:08:43.171Z"
   },
   {
    "duration": 1442,
    "start_time": "2023-03-27T06:05:10.832Z"
   },
   {
    "duration": 3870,
    "start_time": "2023-03-27T06:05:12.983Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-27T06:05:18.287Z"
   },
   {
    "duration": 223,
    "start_time": "2023-03-27T06:05:21.216Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:07:53.970Z"
   },
   {
    "duration": 6102,
    "start_time": "2023-03-27T06:08:10.242Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T06:08:37.099Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T06:08:41.795Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-27T06:08:50.154Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:10:10.852Z"
   },
   {
    "duration": 114,
    "start_time": "2023-03-27T06:11:07.422Z"
   },
   {
    "duration": 97,
    "start_time": "2023-03-27T06:11:40.244Z"
   },
   {
    "duration": 95,
    "start_time": "2023-03-27T06:11:47.911Z"
   },
   {
    "duration": 103,
    "start_time": "2023-03-27T06:12:04.998Z"
   },
   {
    "duration": 156,
    "start_time": "2023-03-27T06:12:12.991Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-27T06:12:18.375Z"
   },
   {
    "duration": 104,
    "start_time": "2023-03-27T06:12:23.966Z"
   },
   {
    "duration": 104,
    "start_time": "2023-03-27T06:12:40.151Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-27T06:12:45.720Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-27T06:13:04.264Z"
   },
   {
    "duration": 276,
    "start_time": "2023-03-27T06:14:02.538Z"
   },
   {
    "duration": 120,
    "start_time": "2023-03-27T06:14:10.077Z"
   },
   {
    "duration": 106,
    "start_time": "2023-03-27T06:14:44.681Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-27T06:15:10.986Z"
   },
   {
    "duration": 103,
    "start_time": "2023-03-27T06:15:32.708Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:16:15.659Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:17:10.076Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T06:17:47.829Z"
   },
   {
    "duration": 117,
    "start_time": "2023-03-27T06:18:27.518Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-27T06:18:46.750Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-27T06:20:49.639Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-27T06:20:52.895Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T06:20:54.824Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-27T06:21:06.263Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-27T06:21:19.408Z"
   },
   {
    "duration": 1353,
    "start_time": "2023-03-27T06:22:51.498Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-27T06:23:04.273Z"
   },
   {
    "duration": 1672,
    "start_time": "2023-03-27T06:23:22.514Z"
   },
   {
    "duration": 4106,
    "start_time": "2023-03-27T06:23:26.441Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-27T06:23:31.875Z"
   },
   {
    "duration": 261,
    "start_time": "2023-03-27T06:23:34.450Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:23:36.537Z"
   },
   {
    "duration": 6404,
    "start_time": "2023-03-27T06:23:38.697Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T06:23:46.578Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-27T06:23:50.466Z"
   },
   {
    "duration": 86,
    "start_time": "2023-03-27T06:23:54.817Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:23:56.690Z"
   },
   {
    "duration": 134,
    "start_time": "2023-03-27T06:23:58.362Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-27T06:24:00.907Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:24:03.411Z"
   },
   {
    "duration": 127,
    "start_time": "2023-03-27T06:24:05.034Z"
   },
   {
    "duration": 1318,
    "start_time": "2023-03-27T06:24:07.562Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-27T06:24:27.651Z"
   },
   {
    "duration": 1441,
    "start_time": "2023-03-27T06:24:53.997Z"
   },
   {
    "duration": 4046,
    "start_time": "2023-03-27T06:24:56.763Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-27T06:25:02.979Z"
   },
   {
    "duration": 246,
    "start_time": "2023-03-27T06:25:05.251Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T06:25:07.611Z"
   },
   {
    "duration": 6729,
    "start_time": "2023-03-27T06:25:09.627Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-27T06:25:17.756Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:25:19.955Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-27T06:25:21.755Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T06:25:24.133Z"
   },
   {
    "duration": 151,
    "start_time": "2023-03-27T06:25:25.667Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-27T06:25:28.547Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T06:25:30.796Z"
   },
   {
    "duration": 108,
    "start_time": "2023-03-27T06:25:32.292Z"
   },
   {
    "duration": 1288,
    "start_time": "2023-03-27T06:25:34.619Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-27T06:25:54.196Z"
   },
   {
    "duration": 1382,
    "start_time": "2023-03-27T06:26:25.108Z"
   },
   {
    "duration": 3947,
    "start_time": "2023-03-27T06:26:27.412Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-27T06:26:32.948Z"
   },
   {
    "duration": 240,
    "start_time": "2023-03-27T06:26:35.175Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-27T06:26:37.165Z"
   },
   {
    "duration": 6673,
    "start_time": "2023-03-27T06:26:39.339Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-27T06:26:46.013Z"
   },
   {
    "duration": 61,
    "start_time": "2023-03-27T06:26:48.774Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T06:26:50.669Z"
   },
   {
    "duration": 117,
    "start_time": "2023-03-27T06:26:52.687Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-27T06:26:54.885Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:26:56.964Z"
   },
   {
    "duration": 192,
    "start_time": "2023-03-27T06:26:59.029Z"
   },
   {
    "duration": 1297,
    "start_time": "2023-03-27T06:27:01.997Z"
   },
   {
    "duration": 211,
    "start_time": "2023-03-27T06:27:13.300Z"
   },
   {
    "duration": 5859,
    "start_time": "2023-03-27T06:27:22.017Z"
   },
   {
    "duration": 128,
    "start_time": "2023-03-27T06:27:29.748Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-27T06:28:13.502Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-27T06:28:16.127Z"
   },
   {
    "duration": 1368,
    "start_time": "2023-03-27T06:28:55.576Z"
   },
   {
    "duration": 3793,
    "start_time": "2023-03-27T06:28:58.351Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-27T06:29:04.943Z"
   },
   {
    "duration": 228,
    "start_time": "2023-03-27T06:29:07.711Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:29:10.040Z"
   },
   {
    "duration": 6184,
    "start_time": "2023-03-27T06:29:12.184Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T06:29:20.688Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T06:29:22.983Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-27T06:29:27.776Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:30:15.818Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T06:30:18.946Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T06:31:14.619Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:34:55.725Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:35:11.086Z"
   },
   {
    "duration": 115,
    "start_time": "2023-03-27T06:35:12.830Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-27T06:35:15.952Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:35:18.414Z"
   },
   {
    "duration": 110,
    "start_time": "2023-03-27T06:35:21.494Z"
   },
   {
    "duration": 1205,
    "start_time": "2023-03-27T06:35:25.014Z"
   },
   {
    "duration": 216,
    "start_time": "2023-03-27T06:35:59.398Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T06:36:12.399Z"
   },
   {
    "duration": 1372,
    "start_time": "2023-03-27T06:38:28.577Z"
   },
   {
    "duration": 3807,
    "start_time": "2023-03-27T06:38:31.032Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-27T06:38:36.177Z"
   },
   {
    "duration": 229,
    "start_time": "2023-03-27T06:38:38.960Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:38:40.889Z"
   },
   {
    "duration": 5868,
    "start_time": "2023-03-27T06:38:43.080Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:38:50.353Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T06:38:52.744Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-27T06:38:54.904Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:38:56.769Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:38:59.553Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:39:03.904Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-27T06:39:08.025Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:39:15.049Z"
   },
   {
    "duration": 214,
    "start_time": "2023-03-27T06:39:21.153Z"
   },
   {
    "duration": 1233,
    "start_time": "2023-03-27T06:39:24.169Z"
   },
   {
    "duration": 107,
    "start_time": "2023-03-27T06:39:45.969Z"
   },
   {
    "duration": 5035,
    "start_time": "2023-03-27T06:40:11.178Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-27T06:42:25.797Z"
   },
   {
    "duration": 1433,
    "start_time": "2023-03-27T06:42:52.148Z"
   },
   {
    "duration": 3973,
    "start_time": "2023-03-27T06:42:54.925Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-27T06:42:59.709Z"
   },
   {
    "duration": 224,
    "start_time": "2023-03-27T06:43:01.988Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T06:43:03.948Z"
   },
   {
    "duration": 6319,
    "start_time": "2023-03-27T06:43:06.229Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T06:43:14.796Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:43:52.734Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-27T06:43:55.086Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:43:57.126Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:43:59.583Z"
   },
   {
    "duration": 122,
    "start_time": "2023-03-27T06:44:01.190Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-27T06:44:03.510Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:44:06.283Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-27T06:44:08.246Z"
   },
   {
    "duration": 145,
    "start_time": "2023-03-27T06:44:11.694Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-27T06:48:47.138Z"
   },
   {
    "duration": 115,
    "start_time": "2023-03-27T06:48:48.890Z"
   },
   {
    "duration": 1355,
    "start_time": "2023-03-27T06:58:53.294Z"
   },
   {
    "duration": 723,
    "start_time": "2023-03-27T06:58:55.902Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-27T06:58:57.958Z"
   },
   {
    "duration": 226,
    "start_time": "2023-03-27T06:59:00.527Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:59:02.854Z"
   },
   {
    "duration": 6150,
    "start_time": "2023-03-27T06:59:04.630Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T06:59:12.382Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T06:59:15.039Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-27T06:59:16.846Z"
   },
   {
    "duration": 64,
    "start_time": "2023-03-27T06:59:20.054Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:59:22.262Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T06:59:24.399Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T06:59:26.926Z"
   },
   {
    "duration": 123,
    "start_time": "2023-03-27T06:59:28.518Z"
   },
   {
    "duration": 49,
    "start_time": "2023-03-27T06:59:31.519Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T06:59:34.015Z"
   },
   {
    "duration": 105,
    "start_time": "2023-03-27T06:59:35.679Z"
   },
   {
    "duration": 168,
    "start_time": "2023-03-27T06:59:38.887Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T06:59:44.380Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-27T07:02:11.818Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:03:08.283Z"
   },
   {
    "duration": 1846,
    "start_time": "2023-03-27T07:03:10.003Z"
   },
   {
    "duration": 1782,
    "start_time": "2023-03-27T07:03:42.986Z"
   },
   {
    "duration": 1940,
    "start_time": "2023-03-27T07:04:01.579Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-27T07:06:54.032Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-27T07:09:45.922Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-27T07:10:12.602Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-27T07:11:39.965Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:12:23.829Z"
   },
   {
    "duration": 1427,
    "start_time": "2023-03-27T07:12:39.757Z"
   },
   {
    "duration": 1316,
    "start_time": "2023-03-27T07:17:25.722Z"
   },
   {
    "duration": 751,
    "start_time": "2023-03-27T07:17:28.274Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-27T07:17:30.609Z"
   },
   {
    "duration": 217,
    "start_time": "2023-03-27T07:17:32.962Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:17:35.122Z"
   },
   {
    "duration": 5918,
    "start_time": "2023-03-27T07:17:37.155Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:17:43.075Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T07:17:45.035Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-27T07:17:47.298Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T07:17:49.163Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:17:51.410Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:17:53.242Z"
   },
   {
    "duration": 122,
    "start_time": "2023-03-27T07:17:55.403Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-27T07:17:57.603Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:17:59.466Z"
   },
   {
    "duration": 103,
    "start_time": "2023-03-27T07:18:01.491Z"
   },
   {
    "duration": 153,
    "start_time": "2023-03-27T07:18:58.219Z"
   },
   {
    "duration": 1235,
    "start_time": "2023-03-27T07:19:04.699Z"
   },
   {
    "duration": 157,
    "start_time": "2023-03-27T07:19:13.764Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:19:34.020Z"
   },
   {
    "duration": 1475,
    "start_time": "2023-03-27T07:20:29.534Z"
   },
   {
    "duration": 3788,
    "start_time": "2023-03-27T07:20:32.077Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-27T07:20:36.461Z"
   },
   {
    "duration": 236,
    "start_time": "2023-03-27T07:20:38.941Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:20:40.949Z"
   },
   {
    "duration": 5970,
    "start_time": "2023-03-27T07:20:42.901Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T07:20:48.873Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:20:51.317Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-27T07:20:53.933Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T07:20:55.813Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:20:58.014Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:21:00.094Z"
   },
   {
    "duration": 117,
    "start_time": "2023-03-27T07:21:01.879Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-27T07:21:04.166Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:21:07.221Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-27T07:21:08.830Z"
   },
   {
    "duration": 226,
    "start_time": "2023-03-27T07:21:33.438Z"
   },
   {
    "duration": 107,
    "start_time": "2023-03-27T07:21:52.903Z"
   },
   {
    "duration": 1214,
    "start_time": "2023-03-27T07:22:44.231Z"
   },
   {
    "duration": 4932,
    "start_time": "2023-03-27T07:22:56.823Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-27T07:23:39.017Z"
   },
   {
    "duration": 1363,
    "start_time": "2023-03-27T07:24:48.786Z"
   },
   {
    "duration": 3739,
    "start_time": "2023-03-27T07:24:51.449Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-27T07:24:57.283Z"
   },
   {
    "duration": 230,
    "start_time": "2023-03-27T07:24:59.754Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:25:01.994Z"
   },
   {
    "duration": 5819,
    "start_time": "2023-03-27T07:25:04.249Z"
   },
   {
    "duration": 1332,
    "start_time": "2023-03-27T07:26:28.831Z"
   },
   {
    "duration": 718,
    "start_time": "2023-03-27T07:26:32.747Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-27T07:26:34.708Z"
   },
   {
    "duration": 231,
    "start_time": "2023-03-27T07:26:37.123Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:26:39.499Z"
   },
   {
    "duration": 6017,
    "start_time": "2023-03-27T07:26:41.316Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:26:48.860Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T07:26:56.619Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-27T07:26:58.979Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:27:01.571Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:27:13.076Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-27T07:27:14.668Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-27T07:27:16.852Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:27:19.283Z"
   },
   {
    "duration": 114,
    "start_time": "2023-03-27T07:27:20.973Z"
   },
   {
    "duration": 220,
    "start_time": "2023-03-27T07:27:35.748Z"
   },
   {
    "duration": 1207,
    "start_time": "2023-03-27T07:28:07.940Z"
   },
   {
    "duration": 5125,
    "start_time": "2023-03-27T07:28:13.884Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-27T07:29:01.358Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:29:03.677Z"
   },
   {
    "duration": 1350,
    "start_time": "2023-03-27T07:29:18.910Z"
   },
   {
    "duration": 3768,
    "start_time": "2023-03-27T07:29:21.573Z"
   },
   {
    "duration": 34,
    "start_time": "2023-03-27T07:29:25.343Z"
   },
   {
    "duration": 220,
    "start_time": "2023-03-27T07:29:26.501Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:29:29.325Z"
   },
   {
    "duration": 6045,
    "start_time": "2023-03-27T07:29:31.342Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T07:29:37.389Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T07:29:39.606Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-27T07:29:42.030Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T07:29:43.797Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:29:45.476Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:29:47.700Z"
   },
   {
    "duration": 110,
    "start_time": "2023-03-27T07:29:49.439Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-27T07:29:51.873Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:29:54.096Z"
   },
   {
    "duration": 103,
    "start_time": "2023-03-27T07:29:56.527Z"
   },
   {
    "duration": 231,
    "start_time": "2023-03-27T07:30:00.098Z"
   },
   {
    "duration": 1219,
    "start_time": "2023-03-27T07:30:02.761Z"
   },
   {
    "duration": 4843,
    "start_time": "2023-03-27T07:30:05.543Z"
   },
   {
    "duration": 117,
    "start_time": "2023-03-27T07:31:18.739Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:31:33.224Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:31:35.075Z"
   },
   {
    "duration": 1432,
    "start_time": "2023-03-27T07:32:59.738Z"
   },
   {
    "duration": 3758,
    "start_time": "2023-03-27T07:33:02.410Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-27T07:33:06.865Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-27T07:33:09.046Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T07:33:11.250Z"
   },
   {
    "duration": 6195,
    "start_time": "2023-03-27T07:33:13.110Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:33:20.611Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-27T07:33:22.834Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-27T07:33:25.210Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T07:33:26.826Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:33:28.514Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T07:33:30.746Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-27T07:33:32.683Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-27T07:33:34.806Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:33:37.226Z"
   },
   {
    "duration": 104,
    "start_time": "2023-03-27T07:33:38.746Z"
   },
   {
    "duration": 7331,
    "start_time": "2023-03-27T07:33:43.643Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-27T07:34:00.555Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-27T07:34:20.332Z"
   },
   {
    "duration": 724,
    "start_time": "2023-03-27T07:36:11.630Z"
   },
   {
    "duration": 1390,
    "start_time": "2023-03-27T07:36:23.070Z"
   },
   {
    "duration": 754,
    "start_time": "2023-03-27T07:36:25.365Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-27T07:36:27.933Z"
   },
   {
    "duration": 235,
    "start_time": "2023-03-27T07:36:30.734Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:36:32.613Z"
   },
   {
    "duration": 6116,
    "start_time": "2023-03-27T07:36:35.402Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T07:36:41.520Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-27T07:36:52.126Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-27T07:37:12.607Z"
   },
   {
    "duration": 71,
    "start_time": "2023-03-27T07:37:14.518Z"
   },
   {
    "duration": 9662,
    "start_time": "2023-03-27T07:37:38.439Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:38:04.614Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:38:07.271Z"
   },
   {
    "duration": 116,
    "start_time": "2023-03-27T07:38:09.335Z"
   },
   {
    "duration": 134,
    "start_time": "2023-03-27T07:38:11.640Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-27T07:39:43.401Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:41:07.850Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-27T07:42:13.702Z"
   },
   {
    "duration": 1355,
    "start_time": "2023-03-27T07:43:10.453Z"
   },
   {
    "duration": 721,
    "start_time": "2023-03-27T07:43:12.837Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-27T07:43:15.844Z"
   },
   {
    "duration": 223,
    "start_time": "2023-03-27T07:43:18.309Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:43:20.774Z"
   },
   {
    "duration": 6016,
    "start_time": "2023-03-27T07:43:22.813Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-27T07:43:30.158Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-27T07:43:32.541Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-27T07:43:35.629Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T07:43:37.797Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T07:43:40.237Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T07:43:42.606Z"
   },
   {
    "duration": 119,
    "start_time": "2023-03-27T07:43:44.262Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-27T07:43:47.102Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T07:43:53.045Z"
   },
   {
    "duration": 105,
    "start_time": "2023-03-27T07:43:55.343Z"
   },
   {
    "duration": 9703,
    "start_time": "2023-03-27T07:43:58.395Z"
   },
   {
    "duration": 134,
    "start_time": "2023-03-27T07:47:13.595Z"
   },
   {
    "duration": 558,
    "start_time": "2023-03-27T07:48:53.195Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-27T07:50:15.902Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:54:32.257Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:55:34.002Z"
   },
   {
    "duration": 52415,
    "start_time": "2023-03-27T07:55:52.274Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T07:57:31.748Z"
   },
   {
    "duration": 137,
    "start_time": "2023-03-27T07:58:15.221Z"
   },
   {
    "duration": 111,
    "start_time": "2023-03-27T07:58:29.317Z"
   },
   {
    "duration": 108,
    "start_time": "2023-03-27T08:00:27.607Z"
   },
   {
    "duration": 108,
    "start_time": "2023-03-27T08:00:42.839Z"
   },
   {
    "duration": 9940,
    "start_time": "2023-03-27T08:01:07.360Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-27T08:01:32.111Z"
   },
   {
    "duration": 10027,
    "start_time": "2023-03-27T08:01:33.816Z"
   },
   {
    "duration": 56955,
    "start_time": "2023-03-27T08:11:44.957Z"
   },
   {
    "duration": 54,
    "start_time": "2023-03-27T08:13:43.099Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-27T08:16:58.928Z"
   },
   {
    "duration": 78752,
    "start_time": "2023-03-27T08:18:22.198Z"
   },
   {
    "duration": 406,
    "start_time": "2023-03-27T08:20:54.333Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-27T08:31:20.744Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-27T08:31:31.247Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T08:32:07.351Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T08:32:31.083Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-27T08:33:30.488Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-27T08:38:17.013Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-27T08:39:52.282Z"
   },
   {
    "duration": 126,
    "start_time": "2023-03-27T08:55:51.296Z"
   },
   {
    "duration": 4694,
    "start_time": "2023-03-27T08:56:47.048Z"
   },
   {
    "duration": 4440,
    "start_time": "2023-03-27T08:56:52.065Z"
   },
   {
    "duration": 155,
    "start_time": "2023-03-27T09:00:15.964Z"
   },
   {
    "duration": 4311,
    "start_time": "2023-03-27T09:01:36.342Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T09:03:27.759Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T09:03:35.159Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-27T09:04:55.024Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-27T09:04:58.128Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-27T09:08:22.636Z"
   },
   {
    "duration": 420,
    "start_time": "2023-03-27T09:08:46.765Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T09:09:49.661Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-27T09:29:11.213Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-27T09:36:22.503Z"
   },
   {
    "duration": 1373,
    "start_time": "2023-03-27T09:49:57.309Z"
   },
   {
    "duration": 732,
    "start_time": "2023-03-27T09:50:00.544Z"
   },
   {
    "duration": 44,
    "start_time": "2023-03-27T09:50:02.612Z"
   },
   {
    "duration": 224,
    "start_time": "2023-03-27T09:50:05.218Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-27T09:50:07.825Z"
   },
   {
    "duration": 6603,
    "start_time": "2023-03-27T09:50:12.912Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-27T09:50:23.737Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-27T09:50:26.537Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-27T09:50:29.345Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T09:50:31.144Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-27T09:50:33.945Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T09:51:14.415Z"
   },
   {
    "duration": 145,
    "start_time": "2023-03-27T09:51:17.005Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-27T09:51:19.580Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T09:51:22.354Z"
   },
   {
    "duration": 126,
    "start_time": "2023-03-27T09:51:24.227Z"
   },
   {
    "duration": 156,
    "start_time": "2023-03-27T09:51:47.851Z"
   },
   {
    "duration": 10351,
    "start_time": "2023-03-27T09:51:56.012Z"
   },
   {
    "duration": 57716,
    "start_time": "2023-03-27T09:52:13.652Z"
   },
   {
    "duration": 11368,
    "start_time": "2023-03-27T09:53:15.548Z"
   },
   {
    "duration": 63087,
    "start_time": "2023-03-27T09:53:37.011Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-27T10:00:11.937Z"
   },
   {
    "duration": 81659,
    "start_time": "2023-03-27T10:01:43.245Z"
   },
   {
    "duration": 424,
    "start_time": "2023-03-27T10:03:09.636Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-27T10:03:17.291Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-27T10:03:20.324Z"
   },
   {
    "duration": 1972,
    "start_time": "2023-03-28T07:21:50.596Z"
   },
   {
    "duration": 2556,
    "start_time": "2023-03-28T07:21:54.707Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-28T07:21:58.554Z"
   },
   {
    "duration": 2329,
    "start_time": "2023-03-28T07:22:32.715Z"
   },
   {
    "duration": 362,
    "start_time": "2023-03-28T07:22:37.252Z"
   },
   {
    "duration": 1157,
    "start_time": "2023-03-28T07:22:44.757Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-28T07:22:48.765Z"
   },
   {
    "duration": 278,
    "start_time": "2023-03-28T07:22:51.924Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-28T07:22:54.980Z"
   },
   {
    "duration": 951,
    "start_time": "2023-03-28T07:23:40.926Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-28T07:23:45.917Z"
   },
   {
    "duration": 624,
    "start_time": "2023-03-28T07:25:47.343Z"
   },
   {
    "duration": 1537,
    "start_time": "2023-03-28T07:26:06.657Z"
   },
   {
    "duration": 144,
    "start_time": "2023-03-28T07:28:47.139Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-28T07:28:58.546Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-28T07:29:50.850Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-28T07:29:56.483Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-28T07:29:59.467Z"
   },
   {
    "duration": 1200745,
    "start_time": "2023-03-28T07:30:01.364Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-28T07:59:17.529Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T07:59:33.673Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-28T08:00:16.419Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-28T08:01:16.619Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-28T08:01:18.811Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T08:03:05.981Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T08:03:43.989Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-28T08:04:14.110Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-28T08:10:24.093Z"
   },
   {
    "duration": 4990,
    "start_time": "2023-03-28T08:11:06.054Z"
   },
   {
    "duration": 1842,
    "start_time": "2023-03-29T05:21:46.820Z"
   },
   {
    "duration": 2921,
    "start_time": "2023-03-29T05:21:48.664Z"
   },
   {
    "duration": 49,
    "start_time": "2023-03-29T05:21:51.587Z"
   },
   {
    "duration": 245,
    "start_time": "2023-03-29T05:21:53.913Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-29T05:21:56.138Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-29T05:22:55.483Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-29T05:25:35.213Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-29T05:26:31.615Z"
   },
   {
    "duration": 663,
    "start_time": "2023-03-29T05:26:40.063Z"
   },
   {
    "duration": 122,
    "start_time": "2023-03-29T05:26:50.911Z"
   },
   {
    "duration": 1518,
    "start_time": "2023-03-29T05:27:18.303Z"
   },
   {
    "duration": 974,
    "start_time": "2023-03-29T05:27:20.822Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-29T05:27:23.934Z"
   },
   {
    "duration": 244,
    "start_time": "2023-03-29T05:27:27.551Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-29T05:27:29.575Z"
   },
   {
    "duration": 30,
    "start_time": "2023-03-29T05:27:40.735Z"
   },
   {
    "duration": 258,
    "start_time": "2023-03-29T05:27:42.952Z"
   },
   {
    "duration": 133,
    "start_time": "2023-03-29T05:27:52.015Z"
   },
   {
    "duration": 1463,
    "start_time": "2023-03-29T05:28:50.737Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T05:28:54.376Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T05:29:38.170Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-29T05:29:40.057Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T05:29:47.500Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T05:29:49.178Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-29T05:29:50.977Z"
   },
   {
    "duration": 108,
    "start_time": "2023-03-29T05:30:25.042Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-29T05:30:51.355Z"
   },
   {
    "duration": 1312952,
    "start_time": "2023-03-29T05:30:56.909Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-29T06:17:18.117Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T06:17:21.053Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T06:18:59.558Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T06:19:04.216Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T06:19:08.335Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-29T06:31:28.655Z"
   },
   {
    "duration": 115,
    "start_time": "2023-03-29T06:33:00.343Z"
   },
   {
    "duration": 30,
    "start_time": "2023-03-29T06:33:09.048Z"
   },
   {
    "duration": 85,
    "start_time": "2023-03-29T06:33:10.951Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-29T06:33:14.784Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T06:33:16.810Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-29T06:33:19.960Z"
   },
   {
    "duration": 139,
    "start_time": "2023-03-29T06:36:21.914Z"
   },
   {
    "duration": 133,
    "start_time": "2023-03-29T06:38:29.111Z"
   },
   {
    "duration": 234,
    "start_time": "2023-03-29T06:40:27.096Z"
   },
   {
    "duration": 90,
    "start_time": "2023-03-29T06:45:16.125Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-29T06:46:32.648Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-29T06:46:44.206Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T06:46:50.175Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-29T06:47:03.376Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-29T06:47:18.073Z"
   },
   {
    "duration": 1493367,
    "start_time": "2023-03-29T06:49:43.427Z"
   },
   {
    "duration": 4992238,
    "start_time": "2023-03-29T07:46:04.997Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T09:15:09.969Z"
   },
   {
    "duration": 30804,
    "start_time": "2023-03-29T09:15:18.627Z"
   },
   {
    "duration": 65251,
    "start_time": "2023-03-29T09:16:47.050Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-29T09:18:21.571Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-29T09:18:43.732Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-29T09:18:50.331Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
